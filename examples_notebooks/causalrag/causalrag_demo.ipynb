{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Search Demo - Query and Context Analysis\n",
    "\n",
    "This notebook demonstrates how to use the Causal Search method in GraphRAG and inspect the context used to generate responses. Causal Search performs causal analysis on knowledge graphs through a two-stage process:\n",
    "\n",
    "1. **Stage 1**: Extract extended graph information (k + s nodes) and generate causal analysis report\n",
    "2. **Stage 2**: Use the causal report to generate final response to user query\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Extended node extraction beyond local search limits\n",
    "- Two-stage processing for comprehensive causal analysis\n",
    "- Automatic output saving to data folders\n",
    "- Configurable parameters for retrieval breadth and context proportions\n",
    "- Integration with existing GraphRAG pipeline\n",
    "- **Context inspection**: See exactly what data was used to generate responses\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. Run the GraphRAG indexing pipeline to generate entities, relationships, and community reports\n",
    "2. Set up your configuration in `settings.yaml` with causal search parameters\n",
    "3. Configured your language models and API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "# GraphRAG imports\n",
    "from graphrag.config.enums import ModelType\n",
    "from graphrag.config.load_config import load_config\n",
    "from graphrag.config.models.language_model_config import LanguageModelConfig\n",
    "from graphrag.language_model.manager import ModelManager\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.factory import get_causal_search_engine\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.structured_search.causal_search.search import CausalSearchError\n",
    "from graphrag.query.structured_search.causal_search.search import CausalSearch\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore\n",
    "\n",
    "# IPython display utilities\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup\n",
    "\n",
    "First, let's load the GraphRAG configuration and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded successfully\n",
      "üìÅ Root directory: /home/chuaxu/projects/graphrag/ragsas\n",
      "üîß Causal search s_parameter: 3\n",
      "üîß Causal search top_k_entities: 10\n",
      "üîß Causal search max_context_tokens: 100000\n"
     ]
    }
   ],
   "source": [
    "# Configuration setup\n",
    "ROOT_DIR = Path(\"/home/chuaxu/projects/graphrag/ragsas\")  # Adjust this path to your project root\n",
    "CONFIG_FILE = None  # Use default settings.yaml\n",
    "\n",
    "# Load configuration\n",
    "try:\n",
    "    config = load_config(ROOT_DIR, CONFIG_FILE)\n",
    "    print(\"‚úÖ Configuration loaded successfully\")\n",
    "    print(f\"üìÅ Root directory: {ROOT_DIR}\")\n",
    "    print(f\"üîß Causal search s_parameter: {config.causal_search.s_parameter}\")\n",
    "    print(f\"üîß Causal search top_k_entities: {config.causal_search.top_k_mapped_entities}\")\n",
    "    print(f\"üîß Causal search max_context_tokens: {config.causal_search.max_context_tokens}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load configuration: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the required data from your GraphRAG pipeline outputs using the same functions as the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading setup\n",
    "INPUT_DIR = f\"{ROOT_DIR}/output\"\n",
    "LANCEDB_URI = f\"{INPUT_DIR}/lancedb\"\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"community_reports\"\n",
    "COMMUNITY_TABLE = \"communities\"\n",
    "ENTITY_TABLE = \"entities\"\n",
    "RELATIONSHIP_TABLE = \"relationships\"\n",
    "COVARIATE_TABLE = \"covariates\"\n",
    "TEXT_UNIT_TABLE = \"text_units\"\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tables to dataframes\n",
    "\n",
    "#### Read entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 3738 entities\n",
      "‚úÖ Loaded 507 communities\n"
     ]
    }
   ],
   "source": [
    "# read nodes table to get community and degree data\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "community_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_TABLE}.parquet\")\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(entity_df)} entities\")\n",
    "print(f\"‚úÖ Loaded {len(community_df)} communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 3917 relationships\n"
     ]
    }
   ],
   "source": [
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "relationships = read_indexer_relationships(relationship_df)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(relationship_df)} relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read other data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è  No covariates found, proceeding without covariates\n",
      "‚úÖ Loaded 995 text units\n",
      "‚úÖ Loaded 484 community reports\n"
     ]
    }
   ],
   "source": [
    "# Load text units\n",
    "text_unit_df = pd.read_parquet(f\"{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet\")\n",
    "text_units = read_indexer_text_units(text_unit_df)\n",
    "\n",
    "# Load community reports\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "reports = read_indexer_reports(report_df, community_df, COMMUNITY_LEVEL)\n",
    "\n",
    "# Load covariates if they exist\n",
    "try:\n",
    "    covariate_df = pd.read_parquet(f\"{INPUT_DIR}/{COVARIATE_TABLE}.parquet\")\n",
    "    claims = read_indexer_covariates(covariate_df)\n",
    "    covariates = {\"claims\": claims}\n",
    "    print(f\"‚úÖ Loaded {len(claims)} covariates\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ÑπÔ∏è  No covariates found, proceeding without covariates\")\n",
    "    covariates = {}\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(text_units)} text units\")\n",
    "print(f\"‚úÖ Loaded {len(reports)} community reports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "Set up the language models and context builder using the same approach as the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models and vector store setup complete\n"
     ]
    }
   ],
   "source": [
    "# Get model configurations from the loaded config\n",
    "chat_model_config = config.get_language_model_config(\"default_chat_model\")\n",
    "embedding_model_config = config.get_language_model_config(\"default_embedding_model\")\n",
    "\n",
    "# Create chat model\n",
    "chat_model = ModelManager().get_or_create_chat_model(\n",
    "    name=\"causal_search\",\n",
    "    model_type=chat_model_config.type,\n",
    "    config=chat_model_config,\n",
    ")\n",
    "\n",
    "# Create token encoder\n",
    "token_encoder = tiktoken.encoding_for_model(chat_model_config.model)\n",
    "\n",
    "# Create embedding model\n",
    "text_embedder = ModelManager().get_or_create_embedding_model(\n",
    "    name=\"causal_search_embedding\",\n",
    "    model_type=embedding_model_config.type,\n",
    "    config=embedding_model_config,\n",
    ")\n",
    "\n",
    "# Create vector store\n",
    "description_embedding_store = LanceDBVectorStore(\n",
    "    collection_name=\"default-entity-description\",\n",
    ")\n",
    "description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "\n",
    "print(\"‚úÖ Models and vector store setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Builder Setup\n",
    "\n",
    "Create the context builder using the same parameters as the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Context builder setup complete\n"
     ]
    }
   ],
   "source": [
    "entities = read_indexer_entities(entity_df, community_df, COMMUNITY_LEVEL)\n",
    "\n",
    "# Context builder parameters (same as visualization notebook)\n",
    "context_builder_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.25,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 3,  # Increased for causal search\n",
    "    \"top_k_relationships\": 3,     # Increased for causal search\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,\n",
    "    \"max_tokens\": 80_000,\n",
    "    # Output control parameters\n",
    "    \"save_network_data\": True,   # Whether to save extracted network data to files\n",
    "    \"save_causal_report\": True,  # Whether to save causal analysis report to files\n",
    "    \"output_folder\": \"causal_search\",  # Subfolder under data/outputs/ for causal search outputs\n",
    "    \"output_base_dir\": str(ROOT_DIR / \"output\"),  # Base output directory\n",
    "}\n",
    "\n",
    "# Create context builder\n",
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=reports,\n",
    "    text_units=text_units,\n",
    "    entities=entities,\n",
    "    relationships=relationships,\n",
    "    covariates=covariates,\n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,\n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Context builder setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Search Engine Setup\n",
    "\n",
    "Create the causal search engine with the same model parameters as the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-20 16:49:41.0019 - INFO - graphrag.query.structured_search.causal_search.search - Loaded causal discovery prompt from GraphRAG prompts\n",
      "2025-08-20 16:49:41.0021 - INFO - graphrag.query.structured_search.causal_search.search - Loaded causal summary prompt from GraphRAG prompts\n",
      "‚úÖ Causal search engine setup complete\n"
     ]
    }
   ],
   "source": [
    "# Model parameters (same as visualization notebook)\n",
    "model_params = {\n",
    "    \"max_tokens\": 16_384,\n",
    "    \"temperature\": 0.0,\n",
    "}\n",
    "\n",
    "# Create causal search engine directly (not using factory function)\n",
    "causal_search_engine = CausalSearch(\n",
    "    model=chat_model,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    model_params=model_params,\n",
    "    context_builder_params=context_builder_params,\n",
    "    s_parameter=3,  # Additional nodes for causal analysis\n",
    "    max_context_tokens=80_000,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Causal search engine setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Search Example\n",
    "\n",
    "Now let's run a causal search query and inspect the context used to generate the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run causal search on sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: How can we use SAS Econometric products to help analyze the impact of different pricing strategies on business revenue?\n",
      "2025-08-20 16:49:41.0036 - INFO - graphrag.query.structured_search.causal_search.search - üöÄ Starting causal search for query: 'How can we use SAS Econometric products to help analyze the impact of different pricing strategies on business revenue?'\n",
      "2025-08-20 16:49:41.0038 - INFO - graphrag.query.structured_search.causal_search.search - üìä Parameters: s_parameter=3, max_context_tokens=80000\n",
      "2025-08-20 16:49:41.0039 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 1: Extracting extended nodes with k=3, s=3\n",
      "2025-08-20 16:49:41.0040 - INFO - graphrag.query.structured_search.causal_search.search - Requesting 12 nodes: (k=3 + s=3) * 2\n",
      "2025-08-20 16:49:41.0612 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Extracted 7 extended nodes (requested: 12)\n",
      "2025-08-20 16:49:41.0613 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 1 complete: Found 7 extended nodes\n",
      "2025-08-20 16:49:41.0614 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 2: Extracting graph information for 7 nodes\n",
      "2025-08-20 16:49:41.0634 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Extracted graph information for 7 nodes\n",
      "2025-08-20 16:49:41.0635 - INFO - graphrag.query.structured_search.causal_search.search - Context length: 33870 chars\n",
      "2025-08-20 16:49:41.0636 - INFO - graphrag.query.structured_search.causal_search.search - Context records: 3 entities, 7 relationships, 3 text units\n",
      "2025-08-20 16:49:41.0637 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 2 complete: Graph context extracted\n",
      "2025-08-20 16:49:41.0638 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 3: Formatting network data for causal discovery prompt\n",
      "2025-08-20 16:49:41.0645 - INFO - graphrag.query.structured_search.causal_search.search - Formatted network data with 3 entities, 7 relationships\n",
      "2025-08-20 16:49:41.0646 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 3 complete: Network data formatted (54267 characters)\n",
      "2025-08-20 16:49:41.0647 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 4: Generating causal report using LLM\n",
      "2025-08-20 16:49:48.0295 - INFO - graphrag.query.structured_search.causal_search.search - Generated causal report of length 3823\n",
      "2025-08-20 16:49:48.0297 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 4 complete: Causal report generated (3823 characters)\n",
      "2025-08-20 16:49:48.0298 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 5: Generating final response using LLM\n",
      "2025-08-20 16:49:52.0831 - INFO - graphrag.query.structured_search.causal_search.search - Generated final response of length 3622\n",
      "2025-08-20 16:49:52.0831 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 5 complete: Final response generated (3622 characters)\n",
      "2025-08-20 16:49:52.0832 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 6: Saving outputs if configured\n",
      "2025-08-20 16:49:52.0836 - INFO - graphrag.query.structured_search.causal_search.search - Saved network data to /home/chuaxu/projects/graphrag/ragsas/output/causal_search/causal_search_network_data_a11a03db_1755722992.json\n",
      "2025-08-20 16:49:52.0838 - INFO - graphrag.query.structured_search.causal_search.search - Saved causal report to /home/chuaxu/projects/graphrag/ragsas/output/causal_search/causal_search_report_a11a03db_1755722992.md\n",
      "2025-08-20 16:49:52.0839 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 6 complete: Outputs saved\n",
      "2025-08-20 16:49:52.0853 - INFO - graphrag.query.structured_search.causal_search.search - üéâ Causal search completed successfully in 11.82s\n",
      "‚úÖ Causal search completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Sample query for causal analysis\n",
    "question = \"How can we use SAS Econometric products to help analyze the impact of different pricing strategies on business revenue?\"\n",
    "print(f\"üîç Query: {question}\")\n",
    "\n",
    "# Execute causal search\n",
    "try:\n",
    "    result = await causal_search_engine.search(question)\n",
    "    print(\"‚úÖ Causal search completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Causal search failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Causal Search Response:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Analyzing the Impact of Pricing Strategies on Business Revenue Using SAS Econometric Products\n",
       "\n",
       "## Introduction\n",
       "\n",
       "SAS Econometric products offer a robust platform for analyzing the impact of various pricing strategies on business revenue. By leveraging the capabilities of procedures such as PROC SEVSELECT and PROC CCDM, businesses can gain insights into how different pricing models affect their financial outcomes. This analysis is crucial for optimizing pricing strategies to maximize revenue and ensure competitive advantage.\n",
       "\n",
       "## Key Procedures and Their Roles\n",
       "\n",
       "### PROC SEVSELECT\n",
       "\n",
       "PROC SEVSELECT is integral to SAS Econometrics, designed for fitting and selecting severity distribution models. It plays a crucial role in estimating regression effects, optimizing objective functions, and handling data with censoring and truncation effects. In the context of pricing strategy analysis, PROC SEVSELECT can be used to model the impact of price changes on revenue distribution, allowing businesses to understand the severity of revenue fluctuations under different pricing scenarios.\n",
       "\n",
       "### PROC CCDM\n",
       "\n",
       "PROC CCDM is a sophisticated procedure within SAS Econometrics used for simulating aggregate loss distributions, particularly in insurance and risk management. It employs Monte Carlo simulation methods to accommodate dependencies on external factors and performs parameter perturbation analysis. For pricing strategy analysis, PROC CCDM can simulate the potential revenue outcomes under various pricing strategies, accounting for external factors such as market conditions and consumer behavior.\n",
       "\n",
       "## Causal Pathways and Integration\n",
       "\n",
       "The interaction between PROC SEVSELECT and PROC CCDM forms a major causal pathway in the analysis of pricing strategies. PROC SEVSELECT generates and manages metadata related to severity regression effects, which is crucial for the operations of PROC CCDM. This metadata serves as a foundational element, enabling PROC CCDM to compute regressor-dependent parameters effectively. The integration between these procedures ensures precise and accurate computations, allowing businesses to simulate and analyze the impact of different pricing strategies on revenue.\n",
       "\n",
       "## Implications for Business Strategy\n",
       "\n",
       "The seamless integration of PROC SEVSELECT and PROC CCDM enhances the accuracy and efficiency of statistical computations, making SAS a powerful tool for analyzing pricing strategies. By understanding the causal relationships within the SAS software suite, businesses can optimize their pricing models to improve revenue outcomes. This analysis can inform strategic decisions, such as adjusting prices in response to market trends or consumer preferences.\n",
       "\n",
       "## Recommendations\n",
       "\n",
       "To leverage SAS Econometric products effectively for pricing strategy analysis, businesses should:\n",
       "\n",
       "- **Invest in Training**: Ensure that staff are well-versed in using PROC SEVSELECT and PROC CCDM to maximize the benefits of these procedures.\n",
       "- **Align Data Management Practices**: Utilize structured data environments, such as MYLIB, to facilitate efficient data handling and analysis.\n",
       "- **Simulate Various Scenarios**: Use PROC CCDM to simulate different pricing strategies and assess their potential impact on revenue, considering external factors.\n",
       "- **Optimize Pricing Models**: Continuously refine pricing strategies based on insights gained from SAS Econometric analysis to enhance revenue and competitive positioning.\n",
       "\n",
       "By adopting these practices, businesses can effectively use SAS Econometric products to analyze and optimize their pricing strategies, ultimately driving improved revenue outcomes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display as formatted Markdown\n",
    "print(\"\\nüìù Causal Search Response:\")\n",
    "print(\"=\" * 50)\n",
    "display(Markdown(result.response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the generated causal search report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Displaying report: causal_search_report_a11a03db_1755722992.md\n",
      "üìÅ Full path: /home/chuaxu/projects/graphrag/ragsas/output/causal_search/causal_search_report_a11a03db_1755722992.md\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Causal Analysis Report\n",
       "\n",
       "**Query:** How can we use SAS Econometric products to help analyze the impact of different pricing strategies on business revenue?\n",
       "\n",
       "**Generated:** 2025-08-20 16:49:52\n",
       "\n",
       "**1. Introduction**\n",
       "\n",
       "This report aims to analyze the causal relationships within the SAS software suite, focusing on the interactions between key procedures such as PROC SEVSELECT and PROC CCDM. The purpose of this analysis is to understand the causal pathways that influence data management and econometric modeling within the SAS environment, and to assess the impact of these relationships on statistical analysis and decision-making processes.\n",
       "\n",
       "**2. Key Entities and Their Roles**\n",
       "\n",
       "- **SAS**: A central entity in the analytics ecosystem, SAS provides a comprehensive platform for data management, statistical modeling, and econometric analysis. It serves as the backbone for various analytical processes across academia, government, and industry.\n",
       "\n",
       "- **PROC SEVSELECT**: This procedure is integral to SAS Econometrics, designed for fitting and selecting severity distribution models. It plays a crucial role in estimating regression effects, optimizing objective functions, and handling data with censoring and truncation effects.\n",
       "\n",
       "- **PROC CCDM**: A sophisticated procedure within SAS Econometrics, PROC CCDM is used for simulating aggregate loss distributions, particularly in insurance and risk management. It employs Monte Carlo simulation methods to accommodate dependencies on external factors and performs parameter perturbation analysis.\n",
       "\n",
       "- **MYLIB**: Functions as a library reference within the SAS environment, MYLIB is essential for storing data tables and models, facilitating efficient data handling and analysis.\n",
       "\n",
       "**3. Major Causal Pathways**\n",
       "\n",
       "The primary causal pathways observed in the network involve the interaction between PROC SEVSELECT and PROC CCDM. PROC SEVSELECT generates and manages metadata related to severity regression effects, which is crucial for the operations of PROC CCDM. This metadata serves as a foundational element, enabling PROC CCDM to compute regressor-dependent parameters effectively. The integration between these procedures highlights a seamless workflow where PROC SEVSELECT's output directly feeds into PROC CCDM's processes, ensuring precise and accurate computations.\n",
       "\n",
       "Additionally, SAS serves as the overarching platform that integrates these procedures, enhancing their functionality and user experience. MYLIB plays a supportive role by providing a structured way to manage datasets within the SAS environment, further facilitating the operations of PROC SEVSELECT and PROC CCDM.\n",
       "\n",
       "**4. Confidence and Evidence Strength**\n",
       "\n",
       "The causal claims presented in this report are supported by the robust integration and functionality of the SAS software suite. The relationships between PROC SEVSELECT and PROC CCDM are well-documented, with PROC SEVSELECT's metadata creation being essential for PROC CCDM's computations. The strength of these claims is bolstered by the extensive use of SAS in various industries, highlighting its reliability and effectiveness in data analysis.\n",
       "\n",
       "**5. Implications and Recommendations**\n",
       "\n",
       "The causal relationships within the SAS software suite have significant implications for data analysis and econometric modeling. The seamless integration of PROC SEVSELECT and PROC CCDM enhances the accuracy and efficiency of statistical computations, making SAS a powerful tool for professionals in insurance, risk management, and other fields requiring complex data analysis.\n",
       "\n",
       "To leverage these causal relationships effectively, organizations should ensure that their data management practices align with the capabilities of SAS procedures. Investing in training and resources to optimize the use of PROC SEVSELECT and PROC CCDM can lead to improved decision-making and analytical outcomes. Additionally, maintaining a structured data environment, such as utilizing MYLIB, can further enhance the efficiency of data processing within the SAS ecosystem."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Report metadata:\n",
      "   - File size: 4,017 bytes\n",
      "   - Last modified: 2025-08-20 20:49:52\n"
     ]
    }
   ],
   "source": [
    "# Find and display the most recent causal search report\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def find_latest_causal_report():\n",
    "    \"\"\"Find the most recent causal search report file.\"\"\"\n",
    "    # Look for causal search reports in the output directory\n",
    "    report_pattern = f\"{ROOT_DIR}/output/causal_search/causal_search_report_*.md\"\n",
    "    report_files = glob.glob(report_pattern)\n",
    "    \n",
    "    if not report_files:\n",
    "        print(\"‚ùå No causal search reports found\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by modification time to get the most recent\n",
    "    latest_report = max(report_files, key=os.path.getmtime)\n",
    "    return latest_report\n",
    "\n",
    "def display_causal_report(report_path):\n",
    "    \"\"\"Display the causal search report as formatted markdown.\"\"\"\n",
    "    if not report_path or not os.path.exists(report_path):\n",
    "        print(\"‚ùå Report file not found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìÑ Displaying report: {os.path.basename(report_path)}\")\n",
    "    print(f\"üìÅ Full path: {report_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        with open(report_path, 'r', encoding='utf-8') as f:\n",
    "            report_content = f.read()\n",
    "        \n",
    "        # Display as formatted Markdown\n",
    "        display(Markdown(report_content))\n",
    "        \n",
    "        # Also show some metadata\n",
    "        file_size = os.path.getsize(report_path)\n",
    "        mod_time = os.path.getmtime(report_path)\n",
    "        mod_time_str = pd.to_datetime(mod_time, unit='s').strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        print(f\"\\nüìä Report metadata:\")\n",
    "        print(f\"   - File size: {file_size:,} bytes\")\n",
    "        print(f\"   - Last modified: {mod_time_str}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading report: {e}\")\n",
    "\n",
    "# Find and display the latest report\n",
    "latest_report_path = find_latest_causal_report()\n",
    "if latest_report_path:\n",
    "    display_causal_report(latest_report_path)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No causal search reports found. Run a causal search query first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Data Loading**: Using the same functions as the visualization notebook\n",
    "2. **Model Setup**: Consistent with the visualization notebook approach\n",
    "3. **Context Building**: Same parameters and structure\n",
    "4. **Causal Search**: Extended node extraction and two-stage processing\n",
    "5. **Context Inspection**: Detailed analysis of what data was used\n",
    "6. **Filtering Analysis**: Understanding how context filtering works\n",
    "\n",
    "The key insight is that causal search uses **intelligent filtering** to ensure:\n",
    "- **LLM Compatibility**: Data fits within model context limits\n",
    "- **Relevance**: Most important entities/relationships are preserved\n",
    "- **Performance**: Efficient processing without context length errors\n",
    "\n",
    "The apparent \"loss\" of data (e.g., 40+ nodes ‚Üí 7 entities) is actually **smart optimization** that preserves the most relevant information while maintaining system stability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
