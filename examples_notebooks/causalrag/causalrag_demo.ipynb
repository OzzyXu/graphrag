{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Search Demo - Query and Context Analysis\n",
    "\n",
    "This notebook demonstrates how to use the Causal Search method in GraphRAG and inspect the context used to generate responses. Causal Search performs causal analysis on knowledge graphs through a two-stage process:\n",
    "\n",
    "1. **Stage 1**: Extract extended graph information (k + s nodes) and generate causal analysis report\n",
    "2. **Stage 2**: Use the causal report to generate final response to user query\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Extended node extraction beyond local search limits\n",
    "- Two-stage processing for comprehensive causal analysis\n",
    "- Automatic output saving to data folders\n",
    "- Configurable parameters for retrieval breadth and context proportions\n",
    "- Integration with existing GraphRAG pipeline\n",
    "- **Context inspection**: See exactly what data was used to generate responses\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. Run the GraphRAG indexing pipeline to generate entities, relationships, and community reports\n",
    "2. Set up your configuration in `settings.yaml` with causal search parameters\n",
    "3. Configured your language models and API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "# GraphRAG imports\n",
    "from graphrag.config.enums import ModelType\n",
    "from graphrag.config.load_config import load_config\n",
    "from graphrag.config.models.language_model_config import LanguageModelConfig\n",
    "from graphrag.language_model.manager import ModelManager\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.factory import get_causal_search_engine\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.structured_search.causal_search.search import CausalSearchError\n",
    "from graphrag.query.structured_search.causal_search.search import CausalSearch\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore\n",
    "\n",
    "# IPython display utilities\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup\n",
    "\n",
    "First, let's load the GraphRAG configuration and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded successfully\n",
      "üìÅ Root directory: /home/chuaxu/projects/graphrag/ragsas\n",
      "üîß Causal search s_parameter: 3\n",
      "üîß Causal search top_k_entities: 10\n",
      "üîß Causal search max_context_tokens: 100000\n"
     ]
    }
   ],
   "source": [
    "# Configuration setup\n",
    "ROOT_DIR = Path(\"/home/chuaxu/projects/graphrag/ragsas\")  # Adjust this path to your project root\n",
    "CONFIG_FILE = None  # Use default settings.yaml\n",
    "\n",
    "# Load configuration\n",
    "try:\n",
    "    config = load_config(ROOT_DIR, CONFIG_FILE)\n",
    "    print(\"‚úÖ Configuration loaded successfully\")\n",
    "    print(f\"üìÅ Root directory: {ROOT_DIR}\")\n",
    "    print(f\"üîß Causal search s_parameter: {config.causal_search.s_parameter}\")\n",
    "    print(f\"üîß Causal search top_k_entities: {config.causal_search.top_k_mapped_entities}\")\n",
    "    print(f\"üîß Causal search max_context_tokens: {config.causal_search.max_context_tokens}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load configuration: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the required data from your GraphRAG pipeline outputs using the same functions as the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading setup\n",
    "INPUT_DIR = f\"{ROOT_DIR}/output\"\n",
    "LANCEDB_URI = f\"{INPUT_DIR}/lancedb\"\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"community_reports\"\n",
    "COMMUNITY_TABLE = \"communities\"\n",
    "ENTITY_TABLE = \"entities\"\n",
    "RELATIONSHIP_TABLE = \"relationships\"\n",
    "COVARIATE_TABLE = \"covariates\"\n",
    "TEXT_UNIT_TABLE = \"text_units\"\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tables to dataframes\n",
    "\n",
    "#### Read entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 3738 entities\n",
      "‚úÖ Loaded 507 communities\n"
     ]
    }
   ],
   "source": [
    "# read nodes table to get community and degree data\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "community_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_TABLE}.parquet\")\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(entity_df)} entities\")\n",
    "print(f\"‚úÖ Loaded {len(community_df)} communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 3917 relationships\n"
     ]
    }
   ],
   "source": [
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "relationships = read_indexer_relationships(relationship_df)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(relationship_df)} relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read other data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è  No covariates found, proceeding without covariates\n",
      "‚úÖ Loaded 995 text units\n",
      "‚úÖ Loaded 484 community reports\n"
     ]
    }
   ],
   "source": [
    "# Load text units\n",
    "text_unit_df = pd.read_parquet(f\"{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet\")\n",
    "text_units = read_indexer_text_units(text_unit_df)\n",
    "\n",
    "# Load community reports\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "reports = read_indexer_reports(report_df, community_df, COMMUNITY_LEVEL)\n",
    "\n",
    "# Load covariates if they exist\n",
    "try:\n",
    "    covariate_df = pd.read_parquet(f\"{INPUT_DIR}/{COVARIATE_TABLE}.parquet\")\n",
    "    claims = read_indexer_covariates(covariate_df)\n",
    "    covariates = {\"claims\": claims}\n",
    "    print(f\"‚úÖ Loaded {len(claims)} covariates\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ÑπÔ∏è  No covariates found, proceeding without covariates\")\n",
    "    covariates = {}\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(text_units)} text units\")\n",
    "print(f\"‚úÖ Loaded {len(reports)} community reports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "Set up the language models and context builder using the same approach as the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models and vector store setup complete\n"
     ]
    }
   ],
   "source": [
    "# Get model configurations from the loaded config\n",
    "chat_model_config = config.get_language_model_config(\"default_chat_model\")\n",
    "embedding_model_config = config.get_language_model_config(\"default_embedding_model\")\n",
    "\n",
    "# Create chat model\n",
    "chat_model = ModelManager().get_or_create_chat_model(\n",
    "    name=\"causal_search\",\n",
    "    model_type=chat_model_config.type,\n",
    "    config=chat_model_config,\n",
    ")\n",
    "\n",
    "# Create token encoder\n",
    "token_encoder = tiktoken.encoding_for_model(chat_model_config.model)\n",
    "\n",
    "# Create embedding model\n",
    "text_embedder = ModelManager().get_or_create_embedding_model(\n",
    "    name=\"causal_search_embedding\",\n",
    "    model_type=embedding_model_config.type,\n",
    "    config=embedding_model_config,\n",
    ")\n",
    "\n",
    "# Create vector store\n",
    "description_embedding_store = LanceDBVectorStore(\n",
    "    collection_name=\"default-entity-description\",\n",
    ")\n",
    "description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "\n",
    "print(\"‚úÖ Models and vector store setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Builder Setup\n",
    "\n",
    "Create the context builder using the same parameters as the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Context builder setup complete\n"
     ]
    }
   ],
   "source": [
    "entities = read_indexer_entities(entity_df, community_df, COMMUNITY_LEVEL)\n",
    "\n",
    "# Context builder parameters (same as visualization notebook)\n",
    "context_builder_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.25,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 3,  # Increased for causal search\n",
    "    \"top_k_relationships\": 3,     # Increased for causal search\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,\n",
    "    \"max_tokens\": 80_000,\n",
    "    # Output control parameters\n",
    "    \"save_network_data\": True,   # Whether to save extracted network data to files\n",
    "    \"save_causal_report\": True,  # Whether to save causal analysis report to files\n",
    "    \"output_folder\": \"causal_search\",  # Subfolder under data/outputs/ for causal search outputs\n",
    "    \"output_base_dir\": str(ROOT_DIR / \"output\"),  # Base output directory\n",
    "}\n",
    "\n",
    "# Create context builder\n",
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=reports,\n",
    "    text_units=text_units,\n",
    "    entities=entities,\n",
    "    relationships=relationships,\n",
    "    covariates=covariates,\n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,\n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Context builder setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Search Engine Setup\n",
    "\n",
    "Create the causal search engine with the same model parameters as the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 11:07:32.0623 - INFO - graphrag.query.structured_search.causal_search.search - Loaded causal discovery prompt from GraphRAG prompts\n",
      "2025-08-18 11:07:32.0626 - INFO - graphrag.query.structured_search.causal_search.search - Loaded causal summary prompt from GraphRAG prompts\n",
      "‚úÖ Causal search engine setup complete\n"
     ]
    }
   ],
   "source": [
    "# Model parameters (same as visualization notebook)\n",
    "model_params = {\n",
    "    \"max_tokens\": 16_384,\n",
    "    \"temperature\": 0.0,\n",
    "}\n",
    "\n",
    "# Create causal search engine directly (not using factory function)\n",
    "causal_search_engine = CausalSearch(\n",
    "    model=chat_model,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    model_params=model_params,\n",
    "    context_builder_params=context_builder_params,\n",
    "    s_parameter=3,  # Additional nodes for causal analysis\n",
    "    max_context_tokens=80_000,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Causal search engine setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Search Example\n",
    "\n",
    "Now let's run a causal search query and inspect the context used to generate the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run causal search on sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: How can we use SAS Econometric products to help analyze the impact of different pricing strategies on business revenue?\n",
      "2025-08-18 11:07:32.0637 - INFO - graphrag.query.structured_search.causal_search.search - üöÄ Starting causal search for query: 'How can we use SAS Econometric products to help analyze the impact of different pricing strategies on business revenue?'\n",
      "2025-08-18 11:07:32.0640 - INFO - graphrag.query.structured_search.causal_search.search - üìä Parameters: s_parameter=3, max_context_tokens=80000\n",
      "2025-08-18 11:07:32.0641 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 1: Extracting extended nodes with k=3, s=3\n",
      "2025-08-18 11:07:32.0642 - INFO - graphrag.query.structured_search.causal_search.search - Requesting 12 nodes: (k=3 + s=3) * 2\n",
      "2025-08-18 11:07:33.0062 - WARNING - graphrag.query.structured_search.local_search.mixed_context - Reached token limit - reverting to previous context state\n",
      "2025-08-18 11:07:33.0082 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Extracted 7 extended nodes (requested: 12)\n",
      "2025-08-18 11:07:33.0083 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 1 complete: Found 7 extended nodes\n",
      "2025-08-18 11:07:33.0084 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 2: Extracting graph information for 7 nodes\n",
      "2025-08-18 11:07:33.0105 - WARNING - graphrag.query.structured_search.local_search.mixed_context - Reached token limit - reverting to previous context state\n",
      "2025-08-18 11:07:33.0118 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Extracted graph information for 7 nodes\n",
      "2025-08-18 11:07:33.0119 - INFO - graphrag.query.structured_search.causal_search.search - Context length: 29384 chars\n",
      "2025-08-18 11:07:33.0122 - INFO - graphrag.query.structured_search.causal_search.search - Context records: 3 entities, 3 relationships, 3 text units\n",
      "2025-08-18 11:07:33.0124 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 2 complete: Graph context extracted\n",
      "2025-08-18 11:07:33.0125 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 3: Formatting network data for causal discovery prompt\n",
      "2025-08-18 11:07:33.0134 - INFO - graphrag.query.structured_search.causal_search.search - Formatted network data with 3 entities, 3 relationships\n",
      "2025-08-18 11:07:33.0135 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 3 complete: Network data formatted (44853 characters)\n",
      "2025-08-18 11:07:33.0136 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 4: Generating causal report using LLM\n",
      "2025-08-18 11:07:38.0693 - INFO - graphrag.query.structured_search.causal_search.search - Generated causal report of length 3713\n",
      "2025-08-18 11:07:38.0694 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 4 complete: Causal report generated (3713 characters)\n",
      "2025-08-18 11:07:38.0695 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 5: Generating final response using LLM\n",
      "2025-08-18 11:07:44.0825 - INFO - graphrag.query.structured_search.causal_search.search - Generated final response of length 3632\n",
      "2025-08-18 11:07:44.0827 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 5 complete: Final response generated (3632 characters)\n",
      "2025-08-18 11:07:44.0827 - INFO - graphrag.query.structured_search.causal_search.search - üîç Step 6: Saving outputs if configured\n",
      "2025-08-18 11:07:44.0829 - INFO - graphrag.query.structured_search.causal_search.search - Saved network data to /home/chuaxu/projects/graphrag/ragsas/output/causal_search/causal_search_network_data_a11a03db_1755529664.json\n",
      "2025-08-18 11:07:44.0831 - INFO - graphrag.query.structured_search.causal_search.search - Saved causal report to /home/chuaxu/projects/graphrag/ragsas/output/causal_search/causal_search_report_a11a03db_1755529664.md\n",
      "2025-08-18 11:07:44.0831 - INFO - graphrag.query.structured_search.causal_search.search - ‚úÖ Step 6 complete: Outputs saved\n",
      "2025-08-18 11:07:44.0843 - INFO - graphrag.query.structured_search.causal_search.search - üéâ Causal search completed successfully in 12.21s\n",
      "‚úÖ Causal search completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Sample query for causal analysis\n",
    "question = \"How can we use SAS Econometric products to help analyze the impact of different pricing strategies on business revenue?\"\n",
    "print(f\"üîç Query: {question}\")\n",
    "\n",
    "# Execute causal search\n",
    "try:\n",
    "    result = await causal_search_engine.search(question)\n",
    "    print(\"‚úÖ Causal search completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Causal search failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Causal Search Response:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Analyzing the Impact of Pricing Strategies on Business Revenue Using SAS Econometric Products\n",
       "\n",
       "## Introduction\n",
       "\n",
       "SAS Econometric products offer a comprehensive suite of tools designed to enhance data analysis capabilities, particularly in econometric modeling and statistical analysis. These tools can be instrumental in analyzing the impact of different pricing strategies on business revenue. By leveraging procedures such as PROC SEVSELECT and PROC CCDM, businesses can gain insights into how pricing adjustments may affect their financial outcomes.\n",
       "\n",
       "## Key Procedures and Their Applications\n",
       "\n",
       "### PROC SEVSELECT\n",
       "\n",
       "**Role and Functionality**: PROC SEVSELECT is pivotal in fitting and selecting severity distribution models. It is particularly adept at handling data with censoring and truncation effects, which are common in revenue data where certain transactions may be incomplete or partially observed.\n",
       "\n",
       "**Application in Pricing Strategy Analysis**: By using PROC SEVSELECT, businesses can model the distribution of revenue outcomes under different pricing scenarios. This procedure allows for the optimization of regression effects, which can help in understanding how changes in pricing influence revenue distribution. The strong causal link between SAS and PROC SEVSELECT, with a weight of 34.0, underscores its importance in econometric analyses.\n",
       "\n",
       "### PROC CCDM\n",
       "\n",
       "**Role and Functionality**: PROC CCDM is designed for simulating aggregate loss distributions using Monte Carlo methods. It is essential for risk management and insurance modeling, providing tools for parameter perturbation analysis and severity adjustment.\n",
       "\n",
       "**Application in Pricing Strategy Analysis**: In the context of pricing strategies, PROC CCDM can simulate the potential revenue outcomes under various pricing models. This simulation capability is crucial for assessing the risk and variability associated with different pricing strategies. The causal link between SAS and PROC CCDM, with a weight of 8.0, highlights its role in comprehensive statistical modeling.\n",
       "\n",
       "## Implications for Business Revenue Analysis\n",
       "\n",
       "The use of SAS Econometric products in analyzing pricing strategies can significantly enhance decision-making processes. By modeling and simulating revenue outcomes, businesses can:\n",
       "\n",
       "- **Optimize Pricing Models**: Use PROC SEVSELECT to identify the most effective pricing strategies that maximize revenue while accounting for data complexities such as censoring and truncation.\n",
       "\n",
       "- **Assess Risk and Variability**: Leverage PROC CCDM to simulate revenue outcomes and assess the risk associated with different pricing strategies, enabling more informed decision-making.\n",
       "\n",
       "## Recommendations\n",
       "\n",
       "To effectively analyze the impact of pricing strategies on business revenue, organizations should:\n",
       "\n",
       "1. **Integrate PROC SEVSELECT and PROC CCDM** into their analytical workflows to optimize data management and enhance decision-making processes.\n",
       "2. **Leverage the robust capabilities** of these procedures to model and simulate revenue outcomes, providing insights into the potential impacts of pricing adjustments.\n",
       "3. **Utilize the insights gained** from these analyses to refine pricing strategies, ultimately driving business growth and revenue optimization.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "SAS Econometric products, with their robust procedures like PROC SEVSELECT and PROC CCDM, offer powerful tools for analyzing the impact of pricing strategies on business revenue. By providing the flexibility and precision needed to address complex analytical challenges, these tools enable businesses to make data-driven decisions that enhance their financial performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display as formatted Markdown\n",
    "print(\"\\nüìù Causal Search Response:\")\n",
    "print(\"=\" * 50)\n",
    "display(Markdown(result.response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the generated causal search report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Displaying report: causal_search_report_a11a03db_1755529664.md\n",
      "üìÅ Full path: /home/chuaxu/projects/graphrag/ragsas/output/causal_search/causal_search_report_a11a03db_1755529664.md\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Causal Analysis Report\n",
       "\n",
       "**Query:** How can we use SAS Econometric products to help analyze the impact of different pricing strategies on business revenue?\n",
       "\n",
       "**Generated:** 2025-08-18 11:07:44\n",
       "\n",
       "**1. Introduction**\n",
       "\n",
       "This report aims to analyze the causal relationships within the SAS software suite, focusing on the procedures PROC SEVSELECT and PROC CCDM. These procedures are integral components of SAS Econometrics, designed to enhance data analysis capabilities, particularly in severity distribution modeling and aggregate loss distribution simulation. The analysis will identify key entities, explore major causal pathways, assess the strength of causal claims, and discuss the implications of these relationships.\n",
       "\n",
       "**2. Key Entities and Their Roles**\n",
       "\n",
       "- **SAS**: As the central entity, SAS provides a comprehensive analytics platform that supports various procedures and tools for statistical analysis. It serves as the backbone for data management and econometric modeling, facilitating complex analytical tasks across academia, industry, and government sectors.\n",
       "\n",
       "- **PROC SEVSELECT**: This procedure is pivotal in fitting and selecting severity distribution models, handling data with censoring and truncation effects, and optimizing regression effects. It contributes significantly to the SAS suite by enhancing model selection and evaluation capabilities, particularly in severity distributions.\n",
       "\n",
       "- **PROC CCDM**: A sophisticated procedure within SAS Econometrics, PROC CCDM is designed for simulating aggregate loss distributions using Monte Carlo methods. It is essential for risk management and insurance modeling, providing tools for parameter perturbation analysis and severity adjustment.\n",
       "\n",
       "**3. Major Causal Pathways**\n",
       "\n",
       "- **SAS to PROC SEVSELECT**: SAS supports PROC SEVSELECT by providing a robust environment for severity distribution modeling. The procedure writes warnings to the SAS log, enhancing user experience and data management capabilities. This relationship is characterized by a strong causal link, with a weight of 34.0, indicating PROC SEVSELECT's integral role within the SAS suite.\n",
       "\n",
       "- **SAS to PROC CCDM**: PROC CCDM is another procedure within the SAS suite, focusing on aggregate loss distribution simulation. The causal link between SAS and PROC CCDM, with a weight of 8.0, highlights its role in comprehensive statistical modeling and risk management.\n",
       "\n",
       "**4. Confidence and Evidence Strength**\n",
       "\n",
       "The causal claims presented in this report are supported by the structured relationships within the SAS software suite. The weights assigned to each relationship (34.0 for PROC SEVSELECT and 8.0 for PROC CCDM) reflect the strength and importance of these procedures within the SAS ecosystem. The detailed descriptions of each procedure further substantiate their roles and contributions to data analysis and econometric modeling.\n",
       "\n",
       "**5. Implications and Recommendations**\n",
       "\n",
       "The causal relationships within the SAS suite have significant implications for data analysis and econometric modeling. PROC SEVSELECT's ability to handle censored and truncated data enhances model selection and evaluation, making it a valuable tool for researchers and analysts. Similarly, PROC CCDM's capabilities in simulating aggregate loss distributions are crucial for risk management and insurance modeling.\n",
       "\n",
       "Recommendations include leveraging PROC SEVSELECT for severity distribution modeling in econometric analyses and utilizing PROC CCDM for comprehensive risk assessment and simulation tasks. Organizations should consider integrating these procedures into their analytical workflows to optimize data management and enhance decision-making processes.\n",
       "\n",
       "In conclusion, the SAS software suite, with its robust procedures, offers powerful tools for statistical analysis and econometric modeling, providing users with the flexibility and precision needed to address complex analytical challenges."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Report metadata:\n",
      "   - File size: 3,907 bytes\n",
      "   - Last modified: 2025-08-18 15:07:44\n"
     ]
    }
   ],
   "source": [
    "# Find and display the most recent causal search report\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def find_latest_causal_report():\n",
    "    \"\"\"Find the most recent causal search report file.\"\"\"\n",
    "    # Look for causal search reports in the output directory\n",
    "    report_pattern = f\"{ROOT_DIR}/output/causal_search/causal_search_report_*.md\"\n",
    "    report_files = glob.glob(report_pattern)\n",
    "    \n",
    "    if not report_files:\n",
    "        print(\"‚ùå No causal search reports found\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by modification time to get the most recent\n",
    "    latest_report = max(report_files, key=os.path.getmtime)\n",
    "    return latest_report\n",
    "\n",
    "def display_causal_report(report_path):\n",
    "    \"\"\"Display the causal search report as formatted markdown.\"\"\"\n",
    "    if not report_path or not os.path.exists(report_path):\n",
    "        print(\"‚ùå Report file not found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìÑ Displaying report: {os.path.basename(report_path)}\")\n",
    "    print(f\"üìÅ Full path: {report_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        with open(report_path, 'r', encoding='utf-8') as f:\n",
    "            report_content = f.read()\n",
    "        \n",
    "        # Display as formatted Markdown\n",
    "        display(Markdown(report_content))\n",
    "        \n",
    "        # Also show some metadata\n",
    "        file_size = os.path.getsize(report_path)\n",
    "        mod_time = os.path.getmtime(report_path)\n",
    "        mod_time_str = pd.to_datetime(mod_time, unit='s').strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        print(f\"\\nüìä Report metadata:\")\n",
    "        print(f\"   - File size: {file_size:,} bytes\")\n",
    "        print(f\"   - Last modified: {mod_time_str}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading report: {e}\")\n",
    "\n",
    "# Find and display the latest report\n",
    "latest_report_path = find_latest_causal_report()\n",
    "if latest_report_path:\n",
    "    display_causal_report(latest_report_path)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No causal search reports found. Run a causal search query first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Data Loading**: Using the same functions as the visualization notebook\n",
    "2. **Model Setup**: Consistent with the visualization notebook approach\n",
    "3. **Context Building**: Same parameters and structure\n",
    "4. **Causal Search**: Extended node extraction and two-stage processing\n",
    "5. **Context Inspection**: Detailed analysis of what data was used\n",
    "6. **Filtering Analysis**: Understanding how context filtering works\n",
    "\n",
    "The key insight is that causal search uses **intelligent filtering** to ensure:\n",
    "- **LLM Compatibility**: Data fits within model context limits\n",
    "- **Relevance**: Most important entities/relationships are preserved\n",
    "- **Performance**: Efficient processing without context length errors\n",
    "\n",
    "The apparent \"loss\" of data (e.g., 40+ nodes ‚Üí 7 entities) is actually **smart optimization** that preserves the most relevant information while maintaining system stability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
